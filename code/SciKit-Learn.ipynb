{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7230c452-0b2e-4f7a-9cda-7a2756640666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "df = pd.read_csv(\"../Dataset_5971.csv\")\n",
    "df.LABEL = df.LABEL.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d16795-40b9-4cc8-9863-cd9a63d82fda",
   "metadata": {},
   "source": [
    "### Pre-processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "630a1a20-fecf-4a13-8585-3585cbdad501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, \n",
    "            phone_token = ' <PHONE> ',\n",
    "            email_token = ' <EMAIL> ',\n",
    "            url_token = ' <URL> ',\n",
    "            num_token = ' <NUM> ',):\n",
    "    \n",
    "    #Capitalization removal\n",
    "    text = text.lower()\n",
    "\n",
    "    #PHONE NUMBER token substitution\n",
    "    text = re.sub(r'(\\(\\d{2}\\))\\s?\\d{8,}|\\d{10,}', \n",
    "                  phone_token, text, flags=re.MULTILINE)\n",
    "    #EMAIL token substitution\n",
    "    text = re.sub(\"([A-Za-z0-9]+[.-_])*[A-Za-z0-9]+@[A-Za-z0-9-]+(\\.[A-Z|a-z]{2,})+\", \n",
    "                  email_token, text, flags=re.MULTILINE)\n",
    "    #URL token substitution\n",
    "    text = re.sub(r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\", \n",
    "                  url_token, text, flags=re.MULTILINE)\n",
    "    #NUMERIC token substitution\n",
    "    text = re.sub(r'[0-9]+', \n",
    "                  num_token, text, flags=re.MULTILINE)\n",
    "    #Special characters removal\n",
    "    text = re.sub(r'([^\\w\\s<>])|(_)', \n",
    "                  \" \", text, flags=re.MULTILINE)\n",
    "    #Multiple space removal\n",
    "    text = re.sub(r'\\s+', \n",
    "                  \" \", text, flags=re.MULTILINE)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1e9faae-43d4-4dfa-91a1-f4911f55b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PREPROCESS'] = df['TEXT'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ba7dbd7-927c-4617-b606-a967eb5e335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.LABEL = df.LABEL.apply(lambda x: x if x==\"smishing\" else \"legitimate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f337d13-1c34-4427-bdf2-40c592465c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(df, test_size=0.2, stratify=df.LABEL, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb05c1-43e0-4b2e-a8a0-619b79ffa35a",
   "metadata": {
    "id": "f1595b07-df89-4fc2-a75d-017ed00e10b5"
   },
   "source": [
    "### Pipeline\n",
    "##### I decided to approach the problem as a basic TEXT -> VECTOR -> CLASSIFIER pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "785b5a18-ef6e-40e7-8748-883a36ad659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bebd0fd-efce-4f15-a1db-b132be7cd984",
   "metadata": {
    "id": "11e76e60-661a-4609-9f1b-c30836999354",
    "tags": []
   },
   "source": [
    "### Grid Search\n",
    "- For the vectorizer, the search involves three parameters (Minimum document frequency, Maximum document frequency and NGRAM range), for those ichoose values that have worked well for me in the past.\n",
    "- As for classifier, we consider 4 well known classifiers for machine learning problems and allow variation of their main parameter mostly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c3878e0-8647-4f21-bf3e-b81760400ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {'vectorizer': (CountVectorizer(), TfidfVectorizer()),\n",
    "     'vectorizer__min_df': (0.01, 0.05, 0.1),\n",
    "     'vectorizer__max_df': (0.5, 0.75, 1.0),\n",
    "     'vectorizer__ngram_range': ((1,1), (1,2), (1,3)),\n",
    "     'classifier': (SGDClassifier(),),\n",
    "     'classifier__penalty': ('l2', 'l1', 'elasticnet')\n",
    "    },\n",
    "    {'vectorizer': (CountVectorizer(), TfidfVectorizer()),\n",
    "     'vectorizer__min_df': (0.01, 0.05, 0.1),\n",
    "     'vectorizer__max_df': (0.5, 0.75, 1.0),\n",
    "     'vectorizer__ngram_range': ((1,1), (1,2), (1,3)),\n",
    "     'classifier': (GaussianNB(),),\n",
    "     'classifier__var_smoothing': (1e-10, 1e-9, 1e-8)\n",
    "    },\n",
    "    {'vectorizer': (CountVectorizer(), TfidfVectorizer()),\n",
    "     'vectorizer__min_df': (0.01, 0.05, 0.1),\n",
    "     'vectorizer__max_df': (0.5, 0.75, 1.0),\n",
    "     'vectorizer__ngram_range': ((1,1), (1,2), (1,3)),\n",
    "     'classifier': (LogisticRegression(),),\n",
    "     'classifier__C': (0.1, 1, 10)\n",
    "    },\n",
    "    {'vectorizer': (CountVectorizer(), TfidfVectorizer()),\n",
    "     'vectorizer__min_df': (0.01, 0.05, 0.1),\n",
    "     'vectorizer__max_df': (0.5, 0.75, 1.0),\n",
    "     'vectorizer__ngram_range': ((1,1), (1,2), (1,3)),\n",
    "     'classifier': (RandomForestClassifier(),),\n",
    "     'classifier__max_depth': (None, 5, 10, 20),\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446ea456-47b6-4430-943f-56735da9e3e0",
   "metadata": {
    "id": "fa0a7add-06f1-4508-aa6a-db3557fffe17"
   },
   "source": [
    "##### The search is performed using a 5 fold crossvalidation strategy which is built in the search object from SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "981710d1-1a10-4f04-bdc1-118f177383a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(pipeline, parameters, cv=5, return_train_score=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09722419-3d69-4a41-bbf0-4f33d8f98bd5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 702 candidates, totalling 3510 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "810 fits failed out of a total of 3510.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "810 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/artur/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/artur/.local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/artur/.local/lib/python3.10/site-packages/sklearn/naive_bayes.py\", line 243, in fit\n",
      "    return self._partial_fit(\n",
      "  File \"/home/artur/.local/lib/python3.10/site-packages/sklearn/naive_bayes.py\", line 400, in _partial_fit\n",
      "    X, y = self._validate_data(X, y, reset=first_call)\n",
      "  File \"/home/artur/.local/lib/python3.10/site-packages/sklearn/base.py\", line 596, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/artur/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/home/artur/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 822, in check_array\n",
      "    array = _ensure_sparse_format(\n",
      "  File \"/home/artur/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 512, in _ensure_sparse_format\n",
      "    raise TypeError(\n",
      "TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.96168394 0.96210169 0.9629396  0.93676773 0.94409757 0.94577231\n",
      " 0.93697912 0.93802449 0.93153563 0.96126421 0.96419549 0.96356853\n",
      " 0.94158361 0.94053758 0.94137418 0.9363491  0.93970186 0.9394909\n",
      " 0.9570777  0.96252076 0.9616824  0.94346908 0.94556288 0.94619137\n",
      " 0.9336279  0.9411652  0.93823413 0.96461478 0.96754606 0.96963986\n",
      " 0.9501689  0.95100769 0.9518456  0.94221319 0.94430787 0.94346996\n",
      " 0.96503319 0.96670814 0.96943066 0.94640145 0.94996057 0.9514261\n",
      " 0.94242218 0.9415847  0.94221341 0.96545204 0.96817411 0.96775592\n",
      " 0.94786677 0.95247366 0.95016955 0.94367938 0.94326031 0.94325966\n",
      " 0.95958772 0.95686631 0.95770422 0.94221275 0.94619072 0.94368004\n",
      " 0.93823413 0.93907139 0.93635107 0.95833096 0.95791408 0.95979846\n",
      " 0.94472497 0.95016846 0.9455631  0.93739863 0.93467743 0.93781594\n",
      " 0.95749326 0.95938005 0.95875068 0.94326053 0.94577318 0.94535368\n",
      " 0.93697912 0.93404631 0.93802537 0.9646139  0.96733685 0.96587088\n",
      " 0.94870424 0.94996035 0.95100747 0.94074788 0.94263314 0.94158404\n",
      " 0.9644047  0.96670814 0.96943044 0.94786611 0.95184495 0.9482854\n",
      " 0.94493483 0.94514403 0.94242218 0.96461303 0.96733641 0.96775461\n",
      " 0.94870468 0.94996079 0.95079848 0.94556332 0.94367894 0.94346908\n",
      " 0.95749721 0.9600092  0.96126487 0.94032728 0.94640102 0.94493373\n",
      " 0.93991062 0.9346748  0.93593113 0.96063769 0.96335845 0.96105523\n",
      " 0.94074679 0.94325944 0.9482843  0.93844487 0.9373971  0.93886175\n",
      " 0.95791693 0.96147407 0.96231155 0.94116695 0.94409757 0.94514316\n",
      " 0.93572324 0.94032816 0.93949024 0.96294026 0.96817433 0.96817455\n",
      " 0.94640189 0.95247322 0.95037985 0.94493417 0.94388793 0.94095687\n",
      " 0.964615   0.96733598 0.96963986 0.94870359 0.95163509 0.95226358\n",
      " 0.94388771 0.94514469 0.94221319 0.96524261 0.9685934  0.96817411\n",
      " 0.94933186 0.95121711 0.95121646 0.94346952 0.94409669 0.94200464\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.95896208 0.96252141 0.96294026 0.94263182 0.94409735 0.94409735\n",
      " 0.93844312 0.93844312 0.93844312 0.95896208 0.96252141 0.96294026\n",
      " 0.94263182 0.94409735 0.94409735 0.93844312 0.93844312 0.93844312\n",
      " 0.95896208 0.96252141 0.96294026 0.94263182 0.94409735 0.94409735\n",
      " 0.93844312 0.93844312 0.93844312 0.93006813 0.92964906 0.92839274\n",
      " 0.92357642 0.92944008 0.92944008 0.92253083 0.92253083 0.92253083\n",
      " 0.93006813 0.92964906 0.92839274 0.92357642 0.92944008 0.92944008\n",
      " 0.92253083 0.92253083 0.92253083 0.93006813 0.92964906 0.92839274\n",
      " 0.92357642 0.92944008 0.92944008 0.92253083 0.92253083 0.92253083\n",
      " 0.9616835  0.96545247 0.96587132 0.94702863 0.94849548 0.94849548\n",
      " 0.94158339 0.94158339 0.94158339 0.9616835  0.96545247 0.96587132\n",
      " 0.94702863 0.94849548 0.94849548 0.94158339 0.94158339 0.94158339\n",
      " 0.9616835  0.96545247 0.96587132 0.94702863 0.94849548 0.94849548\n",
      " 0.94158339 0.94158339 0.94158339 0.96231265 0.96461522 0.96503406\n",
      " 0.94640145 0.95121755 0.95121755 0.94179522 0.94179522 0.94179522\n",
      " 0.96231265 0.96461522 0.96503406 0.94640145 0.95121755 0.95121755\n",
      " 0.94179522 0.94179522 0.94179522 0.96231265 0.96461522 0.96503406\n",
      " 0.94640145 0.95121755 0.95121755 0.94179522 0.94179522 0.94179522\n",
      " 0.96210213 0.96482442 0.96524327 0.94577274 0.94912353 0.94912353\n",
      " 0.94137418 0.94137418 0.94137418 0.96210213 0.96482442 0.96524327\n",
      " 0.94577274 0.94912353 0.94912353 0.94137418 0.94137418 0.94137418\n",
      " 0.96210213 0.96482442 0.96524327 0.94577274 0.94912353 0.94912353\n",
      " 0.94137418 0.94137418 0.94137418 0.96524305 0.96733663 0.9688026\n",
      " 0.94723893 0.95331026 0.95331026 0.94326031 0.94326031 0.94326031\n",
      " 0.96524305 0.96733663 0.9688026  0.94723893 0.95331026 0.95331026\n",
      " 0.94326031 0.94326031 0.94326031 0.96524305 0.96733663 0.9688026\n",
      " 0.94723893 0.95331026 0.95331026 0.94326031 0.94326031 0.94326031\n",
      " 0.97047734 0.96963898 0.96984863 0.96252098 0.96356853 0.96189314\n",
      " 0.9577051  0.95728669 0.95791474 0.9702666  0.9706861  0.96901071\n",
      " 0.96314969 0.96210235 0.96356744 0.95686762 0.95791474 0.95644877\n",
      " 0.96984863 0.9702666  0.97005739 0.96314925 0.96335823 0.96314925\n",
      " 0.95707661 0.95624001 0.95833337 0.97026726 0.96859186 0.96963898\n",
      " 0.95812526 0.96042827 0.9623133  0.9568674  0.95519223 0.95456439\n",
      " 0.96880129 0.97047646 0.96921948 0.95917172 0.96105654 0.96063682\n",
      " 0.95456461 0.95665798 0.95456417 0.96922014 0.97110473 0.96984797\n",
      " 0.96105501 0.96252185 0.96168416 0.95498324 0.95665798 0.95414533\n",
      " 0.94053583 0.9474466  0.94849372 0.95037635 0.94912156 0.94933032\n",
      " 0.95121492 0.95100528 0.95079564 0.93907139 0.94870315 0.94765471\n",
      " 0.94974917 0.94870249 0.94974961 0.9512147  0.9520524  0.94974873\n",
      " 0.94116388 0.95058665 0.94639992 0.95037745 0.95100637 0.94995882\n",
      " 0.95184276 0.95058709 0.9510055  0.94074591 0.95037679 0.95058534\n",
      " 0.94995925 0.94912112 0.94995925 0.95016846 0.94974983 0.95037745\n",
      " 0.94262941 0.94932967 0.94995706 0.94995904 0.94870271 0.95058709\n",
      " 0.95037701 0.95142435 0.95016758 0.94032597 0.94786589 0.94807356\n",
      " 0.94870271 0.94953997 0.94912134 0.94974983 0.9512147  0.95079607\n",
      " 0.96586979 0.9646139  0.96482289 0.95896186 0.96126443 0.96084624\n",
      " 0.96063638 0.95875222 0.95917107 0.96545094 0.96482311 0.96566058\n",
      " 0.9597989  0.96021753 0.96021731 0.96021753 0.95854367 0.958752\n",
      " 0.96587001 0.96545116 0.96607943 0.96000832 0.96105523 0.96021797\n",
      " 0.95917107 0.95938027 0.95854279 0.96293873 0.9627293  0.96566102\n",
      " 0.95875266 0.96084602 0.96126531 0.95791452 0.95728603 0.95561195\n",
      " 0.963567   0.96503275 0.96377599 0.95854257 0.96063725 0.96021753\n",
      " 0.95665754 0.95665907 0.95728647 0.96461346 0.96524174 0.96482311\n",
      " 0.95958948 0.95958926 0.96021797 0.95582116 0.95540165 0.95833271\n",
      " 0.97173257 0.96880173 0.97005783 0.9635681  0.96356788 0.96273018\n",
      " 0.95686784 0.95791496 0.95749589 0.96984863 0.97047646 0.96901049\n",
      " 0.96210257 0.96545204 0.96252141 0.9568674  0.95854279 0.95749611\n",
      " 0.97110451 0.97026704 0.96942912 0.962103   0.96294026 0.96398651\n",
      " 0.9568674  0.95707683 0.95561151 0.96942978 0.96984775 0.96942956\n",
      " 0.95854257 0.96126553 0.96105654 0.95561129 0.95519245 0.95477316\n",
      " 0.96859164 0.96984841 0.96963877 0.95896208 0.96126509 0.96105632\n",
      " 0.95540187 0.9549828  0.9558205  0.96963898 0.96921992 0.97131394\n",
      " 0.95812482 0.96105632 0.96252185 0.9568674  0.95582094 0.95707683]\n",
      "  warnings.warn(\n",
      "/home/artur/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.98084183 0.98324961 0.97838121 0.94393881 0.9478646  0.95053437\n",
      " 0.9386516  0.9389659  0.93566773 0.97602604 0.98136516 0.9838777\n",
      " 0.94645137 0.94755075 0.94687024 0.93786667 0.9380231  0.94079797\n",
      " 0.97916672 0.98356366 0.9824121  0.9487544  0.95430287 0.95079538\n",
      " 0.93865157 0.94064104 0.93760509 0.97780575 0.98057994 0.98105105\n",
      " 0.95105744 0.95634434 0.95571626 0.94383399 0.94488088 0.94566595\n",
      " 0.97832918 0.98094638 0.98105109 0.95163324 0.95461711 0.95597793\n",
      " 0.94299647 0.94493315 0.94414799 0.97864322 0.98063233 0.98073699\n",
      " 0.95158098 0.95660611 0.95561163 0.9444621  0.94331027 0.94404343\n",
      " 0.98246438 0.98555259 0.98513397 0.94734105 0.95215675 0.95168538\n",
      " 0.94126885 0.94001274 0.93995992 0.98319723 0.98591912 0.98539573\n",
      " 0.94849275 0.95090033 0.95241839 0.93739486 0.93959346 0.94016967\n",
      " 0.98272609 0.98518623 0.98623316 0.94577027 0.95084793 0.951738\n",
      " 0.94153034 0.94137382 0.94132125 0.97942835 0.98126052 0.98157456\n",
      " 0.95215671 0.95571626 0.95498344 0.94372925 0.94367683 0.94545659\n",
      " 0.97880031 0.98199326 0.98157454 0.9528372  0.95550692 0.95493108\n",
      " 0.94388629 0.94571832 0.94493324 0.97900962 0.98146983 0.98131283\n",
      " 0.95268016 0.95419824 0.95514045 0.94414798 0.94383398 0.94493326\n",
      " 0.97644467 0.98105126 0.98188882 0.94676551 0.9524709  0.94927788\n",
      " 0.93975081 0.94032671 0.93865173 0.97801508 0.98220282 0.98173175\n",
      " 0.94493326 0.95189509 0.95152871 0.94153051 0.94006502 0.94095501\n",
      " 0.97544988 0.98304017 0.98319733 0.94409558 0.95116215 0.95048186\n",
      " 0.93791842 0.94310108 0.94367676 0.97880022 0.98094641 0.98084163\n",
      " 0.95215678 0.95571626 0.95540217 0.9448808  0.94472385 0.94346764\n",
      " 0.97822454 0.98078934 0.98089407 0.95215663 0.955978   0.95665846\n",
      " 0.94304886 0.94378171 0.94404333 0.97838154 0.98078936 0.98047529\n",
      " 0.95210439 0.95655367 0.95550695 0.94519491 0.9438861  0.94331034\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.9650858  0.96649916 0.96649915 0.94393854 0.94529952 0.94529952\n",
      " 0.94105974 0.94105974 0.94105974 0.9650858  0.96649916 0.96649915\n",
      " 0.94393854 0.94529952 0.94529952 0.94105974 0.94105974 0.94105974\n",
      " 0.9650858  0.96649916 0.96649915 0.94393854 0.94529952 0.94529952\n",
      " 0.94105974 0.94105974 0.94105974 0.93111386 0.93032878 0.93017174\n",
      " 0.92556537 0.92917725 0.92917725 0.92284356 0.92284356 0.92284356\n",
      " 0.93111386 0.93032878 0.93017174 0.92556537 0.92917725 0.92917725\n",
      " 0.92284356 0.92284356 0.92284356 0.93111386 0.93032878 0.93017174\n",
      " 0.92556537 0.92917725 0.92917725 0.92284356 0.92284356 0.92284356\n",
      " 0.97503144 0.9782244  0.97843379 0.94828321 0.95173794 0.95173794\n",
      " 0.94430503 0.94430503 0.94430503 0.97503144 0.9782244  0.97843379\n",
      " 0.94828321 0.95173794 0.95173794 0.94430503 0.94430503 0.94430503\n",
      " 0.97503144 0.9782244  0.97843379 0.94828321 0.95173794 0.95173794\n",
      " 0.94430503 0.94430503 0.94430503 0.96854069 0.97063445 0.97089623\n",
      " 0.94891136 0.9540412  0.9540412  0.94231597 0.94231597 0.94231597\n",
      " 0.96854069 0.97063445 0.97089623 0.94891136 0.9540412  0.9540412\n",
      " 0.94231597 0.94231597 0.94231597 0.96854069 0.97063445 0.97089623\n",
      " 0.94891136 0.9540412  0.9540412  0.94231597 0.94231597 0.94231597\n",
      " 0.98162685 0.98597145 0.98602378 0.94828323 0.95199976 0.95199976\n",
      " 0.94451444 0.94451444 0.94451444 0.98162685 0.98597145 0.98602378\n",
      " 0.94828323 0.95199976 0.95199976 0.94451444 0.94451444 0.94451444\n",
      " 0.98162685 0.98597145 0.98602378 0.94828323 0.95199976 0.95199976\n",
      " 0.94451444 0.94451444 0.94451444 0.97822446 0.98047531 0.98120811\n",
      " 0.95137151 0.95744365 0.95744365 0.94346756 0.94346756 0.94346756\n",
      " 0.97822446 0.98047531 0.98120811 0.95137151 0.95744365 0.95744365\n",
      " 0.94346756 0.94346756 0.94346756 0.97822446 0.98047531 0.98120811\n",
      " 0.95137151 0.95744365 0.95744365 0.94346756 0.94346756 0.94346756\n",
      " 0.99623116 0.99623116 0.99617882 0.99549833 0.99544597 0.99544599\n",
      " 0.98942624 0.98942624 0.98942624 0.99623116 0.99623116 0.99623116\n",
      " 0.99549833 0.99544599 0.99549833 0.98942624 0.98942624 0.98937389\n",
      " 0.99623116 0.99623116 0.99623116 0.99549833 0.99549833 0.99544599\n",
      " 0.98942624 0.98937389 0.98942624 0.99623116 0.99623116 0.99623116\n",
      " 0.99549833 0.99549833 0.99539364 0.9890075  0.9890075  0.9890075\n",
      " 0.99623116 0.99623116 0.99623116 0.99549833 0.99544599 0.99549833\n",
      " 0.9890075  0.9890075  0.9890075  0.99623116 0.99623116 0.99623116\n",
      " 0.99549833 0.99544599 0.99549833 0.9890075  0.9890075  0.9890075\n",
      " 0.94618929 0.95440724 0.9536745  0.95304662 0.95304658 0.95377939\n",
      " 0.95587312 0.95508795 0.95456451 0.94320532 0.95597763 0.95445985\n",
      " 0.95268013 0.95330819 0.95404107 0.95487854 0.95519263 0.95372698\n",
      " 0.94603215 0.95644897 0.95341279 0.95377936 0.95372703 0.95377936\n",
      " 0.95519263 0.95508799 0.95445987 0.94608448 0.95712934 0.9571295\n",
      " 0.95618722 0.95435514 0.95482639 0.95461681 0.955716   0.95592547\n",
      " 0.94666046 0.9576528  0.95634429 0.95603016 0.95472166 0.95419816\n",
      " 0.95508796 0.95576842 0.95566375 0.94686974 0.95634405 0.95534971\n",
      " 0.95529743 0.95487859 0.95514034 0.95498325 0.95639653 0.95534966\n",
      " 0.97539782 0.97607826 0.97743931 0.97801503 0.97906199 0.97937609\n",
      " 0.97853857 0.97780573 0.9783292  0.97545014 0.97628772 0.97743923\n",
      " 0.97911418 0.97817213 0.97900963 0.97874792 0.97780575 0.97832922\n",
      " 0.97571186 0.97613057 0.97665415 0.9788002  0.97906207 0.97864322\n",
      " 0.97806743 0.97801512 0.97827681 0.978905   0.97806744 0.97958537\n",
      " 0.98141749 0.9828308  0.98246441 0.98199335 0.98136526 0.98157467\n",
      " 0.979376   0.97890496 0.97932367 0.98162689 0.98298787 0.98314494\n",
      " 0.98220268 0.98199338 0.98188869 0.9784861  0.97859092 0.97885255\n",
      " 0.98146985 0.98215031 0.98298788 0.98230745 0.98288325 0.98225509\n",
      " 0.99549831 0.99497492 0.99497488 0.9952366  0.99492253 0.99513192\n",
      " 0.98942624 0.98942624 0.98942624 0.99555067 0.99507958 0.99518426\n",
      " 0.99523662 0.99518426 0.99518427 0.98942624 0.98942624 0.98942624\n",
      " 0.99549833 0.99487022 0.99507958 0.99523662 0.99518426 0.99481784\n",
      " 0.98942624 0.98942624 0.98942624 0.99591711 0.99586474 0.99602175\n",
      " 0.99539364 0.99544599 0.99544599 0.9890075  0.9890075  0.9890075\n",
      " 0.99591708 0.99586476 0.99581241 0.99544599 0.99544599 0.99549833\n",
      " 0.9890075  0.98895515 0.9890075  0.99586474 0.99576007 0.99612648\n",
      " 0.99549833 0.99549833 0.99549833 0.9890075  0.9890075  0.9890075 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;, SGDClassifier())]),\n",
       "             param_grid=[{&#x27;classifier&#x27;: (SGDClassifier(),),\n",
       "                          &#x27;classifier__penalty&#x27;: (&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;),\n",
       "                          &#x27;vectorizer&#x27;: (CountVectorizer(), TfidfVectorizer()),\n",
       "                          &#x27;vectorizer__max_df&#x27;: (0.5, 0.75, 1.0),\n",
       "                          &#x27;vectorizer__min_df&#x27;: (0.01, 0.05, 0.1),\n",
       "                          &#x27;vectorizer__ngram_range...\n",
       "                          &#x27;vectorizer__ngram_range&#x27;: ((1, 1), (1, 2), (1, 3))},\n",
       "                         {&#x27;classifier&#x27;: (RandomForestClassifier(max_depth=20),),\n",
       "                          &#x27;classifier__max_depth&#x27;: (None, 5, 10, 20),\n",
       "                          &#x27;vectorizer&#x27;: (CountVectorizer(max_df=0.5,\n",
       "                                                         min_df=0.01),\n",
       "                                         TfidfVectorizer()),\n",
       "                          &#x27;vectorizer__max_df&#x27;: (0.5, 0.75, 1.0),\n",
       "                          &#x27;vectorizer__min_df&#x27;: (0.01, 0.05, 0.1),\n",
       "                          &#x27;vectorizer__ngram_range&#x27;: ((1, 1), (1, 2), (1, 3))}],\n",
       "             return_train_score=True, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;, SGDClassifier())]),\n",
       "             param_grid=[{&#x27;classifier&#x27;: (SGDClassifier(),),\n",
       "                          &#x27;classifier__penalty&#x27;: (&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;),\n",
       "                          &#x27;vectorizer&#x27;: (CountVectorizer(), TfidfVectorizer()),\n",
       "                          &#x27;vectorizer__max_df&#x27;: (0.5, 0.75, 1.0),\n",
       "                          &#x27;vectorizer__min_df&#x27;: (0.01, 0.05, 0.1),\n",
       "                          &#x27;vectorizer__ngram_range...\n",
       "                          &#x27;vectorizer__ngram_range&#x27;: ((1, 1), (1, 2), (1, 3))},\n",
       "                         {&#x27;classifier&#x27;: (RandomForestClassifier(max_depth=20),),\n",
       "                          &#x27;classifier__max_depth&#x27;: (None, 5, 10, 20),\n",
       "                          &#x27;vectorizer&#x27;: (CountVectorizer(max_df=0.5,\n",
       "                                                         min_df=0.01),\n",
       "                                         TfidfVectorizer()),\n",
       "                          &#x27;vectorizer__max_df&#x27;: (0.5, 0.75, 1.0),\n",
       "                          &#x27;vectorizer__min_df&#x27;: (0.01, 0.05, 0.1),\n",
       "                          &#x27;vectorizer__ngram_range&#x27;: ((1, 1), (1, 2), (1, 3))}],\n",
       "             return_train_score=True, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, SGDClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                                       ('classifier', SGDClassifier())]),\n",
       "             param_grid=[{'classifier': (SGDClassifier(),),\n",
       "                          'classifier__penalty': ('l2', 'l1', 'elasticnet'),\n",
       "                          'vectorizer': (CountVectorizer(), TfidfVectorizer()),\n",
       "                          'vectorizer__max_df': (0.5, 0.75, 1.0),\n",
       "                          'vectorizer__min_df': (0.01, 0.05, 0.1),\n",
       "                          'vectorizer__ngram_range...\n",
       "                          'vectorizer__ngram_range': ((1, 1), (1, 2), (1, 3))},\n",
       "                         {'classifier': (RandomForestClassifier(max_depth=20),),\n",
       "                          'classifier__max_depth': (None, 5, 10, 20),\n",
       "                          'vectorizer': (CountVectorizer(max_df=0.5,\n",
       "                                                         min_df=0.01),\n",
       "                                         TfidfVectorizer()),\n",
       "                          'vectorizer__max_df': (0.5, 0.75, 1.0),\n",
       "                          'vectorizer__min_df': (0.01, 0.05, 0.1),\n",
       "                          'vectorizer__ngram_range': ((1, 1), (1, 2), (1, 3))}],\n",
       "             return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(train.PREPROCESS,smishing_model/.LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c365e6ef-8fbf-4bf5-8dfe-66b6491843ff",
   "metadata": {
    "id": "4fbc8d87-68bf-4ea0-a7d0-4fc534f0eb8b"
   },
   "source": [
    "#### Best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00c9fc9a-fc07-4850-ab84-656c8ebdc383",
   "metadata": {
    "id": "8fff69d5-b8de-406b-a367-6cf95aab073d",
    "outputId": "13803bfa-172e-421c-bbf7-69bb36ba13de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer(max_df=0.5, min_df=0.01)),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(max_depth=20))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer(max_df=0.5, min_df=0.01)),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(max_depth=20))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_df=0.5, min_df=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(max_df=0.5, min_df=0.01)),\n",
       "                ('classifier', RandomForestClassifier(max_depth=20))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95c02e3-86d6-40c4-8006-3467dfb26571",
   "metadata": {
    "id": "751fc185-c727-4f37-b217-390eb30dc0e9"
   },
   "source": [
    "- Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebd72dd4-af99-4e8f-908c-ef65e9cdce0e",
   "metadata": {
    "id": "16451f92-1587-4423-9268-5eba2b3a5b39"
   },
   "outputs": [],
   "source": [
    "best_classifier = search.best_estimator_\n",
    "dev[\"PREDICTION\"] = best_classifier.predict(dev.PREPROCESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7818e-165a-4ab3-9d77-cb2925eb0daf",
   "metadata": {
    "id": "b8ef8797-c7aa-4f8f-af1b-d9891829539f"
   },
   "source": [
    "- Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42e91576-738e-420b-83ac-3aa97c368cca",
   "metadata": {
    "id": "3143f2d5-98fe-4edd-a699-ed52588ccecc",
    "outputId": "ecee9aba-f7d5-46a7-f885-e29cf1d2837e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8839285714285714"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(dev.LABEL==\"smishing\", dev.PREDICTION==\"smishing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08e0b927-bcbf-454d-9a7b-bd22c7c85059",
   "metadata": {
    "id": "cbae80f9-46fb-4db6-8b6c-a47f36eaa050",
    "outputId": "bcf0d896-4e4c-41be-fda9-048751096d3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7734375"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(dev.LABEL==\"smishing\", dev.PREDICTION==\"smishing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a4fd138-b4b4-499a-af9a-3c3b33676d71",
   "metadata": {
    "id": "878f4f53-40e6-4602-b596-d4cf2a080199",
    "outputId": "64b12ed5-0b31-4b0f-fd45-65aa3e52ac34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(dev.LABEL==\"smishing\", dev.PREDICTION==\"smishing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "masters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
